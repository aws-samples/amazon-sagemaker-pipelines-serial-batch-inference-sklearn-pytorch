{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b66fcbeb-4291-4028-9656-1f95c52d248e",
   "metadata": {},
   "source": [
    "# Sagemaker Pipelines SKLearn-->SKLearn Serial Batch Inference Demo End to End\n",
    "\n",
    "This notebook demonstrates the end to end process of creating a Sagemaker Pipeline for data preprocessing and model training with scikit-learn, registering the pipeline model, and running serial batch inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ea61d-fcb9-403c-b8c6-dd64977cb377",
   "metadata": {},
   "source": [
    "\n",
    "## Table of Contents\n",
    "1. [Configure AWS](#configure)\n",
    "2. [Load Data](#data)\n",
    "3. [Define Pipeline Parameters](#params)\n",
    "4. [Define a `features.py` script for training and inference](#features)\n",
    "5. [Define a `model.py` script for training and inference](#model)\n",
    "6. [Define model creation and registration steps](#createregister)\n",
    "7. [Configure Sagemaker Pipeline](#pipeline)\n",
    "8. [Execute Sagemaker Pipeline to build features, train model, register artifacts, and create Sagemaker Model](#submit)\n",
    "9. [Pass pipeline to Batch Transform for serial inference](#inference)\n",
    "10. [Download resulting predictions](#download)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64477410-15de-45e4-b143-5d892f8a5eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd72f2e-027c-424c-8ac4-efe210e234b8",
   "metadata": {},
   "source": [
    "### 1. Configure AWS <a name=\"configure\"></a><a name=\"configure\"></a>\n",
    "\n",
    "Set up your Sagemaker Session, Sagemaker Pipeline session, roles, predefined variables, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6a43688-4330-4e1c-b8c8-46b28f264a89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configs:\n",
      "{'DEFAULT_BUCKET': 'sklearn-mlops-inf-pipeline-demo', 'MODEL_PACKAGE_GROUP_NAME': 'PipelineSKLearnModelPackageGroup', 'PREFIX': 'serial-inference-pipeline', 'PIPELINE_NAME': 'serial-inference-pipeline', 'INPUT_DATA': 's3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/housing_data/raw', 'MODEL_APPROVAL_STATUS': 'Approved', 'PROCESSING_INSTANCE_TYPE': 'ml.m5.xlarge', 'PROCESSING_INSTANCE_COUNT': 1, 'TRAINING_INSTANCE_TYPE': 'ml.m5.xlarge', 'CREATE_MODEL_INSTANCE_TYPE': 'ml.m5.large', 'BATCH_TRANSFORM_INSTANCE_COUNT': 1, 'BATCH_TRANSFORM_INSTANCE_TYPE': 'ml.m4.xlarge'}\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "Region: ca-central-1\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "Role: arn:aws:iam::817463428454:role/service-role/AmazonSageMaker-ExecutionRole-20230919T125063\n",
      "Bucket: sklearn-mlops-inf-pipeline-demo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Load configs\n",
    "with open('config.json', 'r') as file:\n",
    "    config_data = json.load(file)\n",
    "print(\"Configs:\")    \n",
    "print(config_data)\n",
    "\n",
    "# Configure boto3, bucket info, and Sagemaker Sessions\n",
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.Session(default_bucket = config_data['DEFAULT_BUCKET'], boto_session=sess)\n",
    "pipeline_session = PipelineSession(default_bucket = config_data['DEFAULT_BUCKET'], boto_session=sess) \n",
    "\n",
    "# Configure region\n",
    "region = sagemaker_session.boto_region_name\n",
    "print(f\"Region: {region}\")\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "print(f\"Role: {role}\")\n",
    "\n",
    "# S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "print(f\"Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41efae8f-7683-40ab-8eca-751c3bfe60d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define prefixes and names\n",
    "model_package_group_name = config_data['MODEL_PACKAGE_GROUP_NAME']\n",
    "prefix = config_data['PREFIX']\n",
    "pipeline_name = config_data['PIPELINE_NAME'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff9b9a3-b80f-4467-9f89-3562c02d3148",
   "metadata": {},
   "source": [
    "### 2. Load Dataset to Studio & Upload to S3 for training <a name=\"data\"></a><a name=\"data\"></a>\n",
    "\n",
    "We use the California housing dataset. More info on the dataset:\n",
    "\n",
    "* This dataset was obtained from the StatLib repository. http://lib.stat.cmu.edu/datasets/\n",
    "* The target variable is the median house value for California districts.\n",
    "* This dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ed5d05d-c61e-49f8-bd6f-a6c28361e092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), \"housing_data\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "raw_dir = os.path.join(os.getcwd(), \"housing_data/raw\")\n",
    "os.makedirs(raw_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5a911ed-f74a-41dd-b85e-6672a6423d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(\n",
    "    f\"sagemaker-example-files-prod-{region}\",\n",
    "    \"datasets/tabular/california_housing/cal_housing.tgz\",\n",
    "    \"cal_housing.tgz\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5cddfe44-b7b3-4269-98f1-27dc12435c10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: CaliforniaHousing/cal_housing.data: Cannot change ownership to uid 10017, gid 166: Operation not permitted\n",
      "tar: CaliforniaHousing/cal_housing.domain: Cannot change ownership to uid 10017, gid 166: Operation not permitted\n",
      "tar: Exiting with failure status due to previous errors\n"
     ]
    }
   ],
   "source": [
    "!tar -zxf cal_housing.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70286ee8-166b-40c7-a0ac-e092085b4701",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/housing_data/raw\n"
     ]
    }
   ],
   "source": [
    "columns = [\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    \"housingMedianAge\",\n",
    "    \"totalRooms\",\n",
    "    \"totalBedrooms\",\n",
    "    \"population\",\n",
    "    \"households\",\n",
    "    \"medianIncome\",\n",
    "    \"medianHouseValue\",\n",
    "]\n",
    "cal_housing_df = pd.read_csv(\"CaliforniaHousing/cal_housing.data\", names=columns, header=None)\n",
    "cal_housing_df[\n",
    "    \"medianHouseValue\"\n",
    "] /= 500000  # Scaling target down to avoid overcomplicating the example\n",
    "cal_housing_df.to_csv(f\"./housing_data/raw/raw_data_all.csv\", header=True, index=False)\n",
    "rawdata_s3_prefix = \"{}/housing_data/raw\".format(prefix)\n",
    "raw_s3 = sagemaker_session.upload_data(path=\"./housing_data/raw/\", key_prefix=rawdata_s3_prefix)\n",
    "print(raw_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bbd6d0-8202-46a7-8886-cd3ead2a793d",
   "metadata": {},
   "source": [
    "### 3. Define Parameters to Parametrize Pipeline Execution <a name=\"params\"></a><a name=\"params\"></a>\n",
    "\n",
    "Define Pipeline parameters that you can use to parametrize the pipeline. Parameters enable custom pipeline executions and schedules without having to modify the Pipeline definition.\n",
    "\n",
    "The supported parameter types include:\n",
    "\n",
    "- ParameterString - represents a str Python type\n",
    "- ParameterInteger - represents an int Python type\n",
    "- ParameterFloat - represents a float Python type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "04ee68a3-0d6b-4c72-bdad-9f159397b772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat\n",
    "\n",
    "# raw input data\n",
    "input_data = ParameterString(name='InputData', default_value=config_data['INPUT_DATA'])\n",
    "\n",
    "# status of newly trained model in registry\n",
    "model_approval_status = ParameterString(name=\"ModelApprovalStatus\", default_value=config_data['MODEL_APPROVAL_STATUS'])\n",
    "\n",
    "# processing step parameters\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\", default_value=config_data['PROCESSING_INSTANCE_TYPE']\n",
    ")\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=config_data['PROCESSING_INSTANCE_COUNT'])\n",
    "\n",
    "# training step parameters\n",
    "training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=config_data['TRAINING_INSTANCE_TYPE'])\n",
    "\n",
    "# create model step parameters \n",
    "create_model_instance_type = ParameterString(name=\"CreateModelInstanceType\", default_value=config_data[\"CREATE_MODEL_INSTANCE_TYPE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048766e-63fc-4147-a5b9-99269c49a5f1",
   "metadata": {},
   "source": [
    "### 4. Feature Build and Inference Script<a name=\"features\"></a><a name=\"features\"></a>\n",
    "\n",
    "Define a Sagemaker processing job for feature engineering, utilizing a scikit-learn StandardScaler(). Save the scaler as a feature artifact during training, and deserialize it for custom inference transformations.\n",
    "\n",
    "#### Script Structure\n",
    "\n",
    "Inside the main guard (`if name == __main__`), provide training code with arguments aligned to Sagemaker Processing Job documentation.\n",
    "\n",
    "Outside the main guard, define four inference functions as expected by Sagemaker:\n",
    "* `input_fn`: reads input data from the relative directory passed into the feature container\n",
    "* `model_fn`: deserializes the tar.gz artifact from the model registry, containing pretrained feature artifact(s)\n",
    "* `predict_fn`: computes the data transformation step for inference data\n",
    "* `output_fn`: sends transformed data to the model step container as JSON\n",
    "\n",
    "Refer to the Sagemaker Python SDK documentation for details. If no custom inference functions are provided, the default Sagemaker inference handler will run.\n",
    "\n",
    "`features.py` is the entry point for data preprocessing functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aa10dee2-3a48-4773-9b75-fc5fab2c3a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8922452d-8118-4cfe-a93a-8a9d78d90c82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/features.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/features.py\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tarfile\n",
    "\n",
    "try:\n",
    "    from sagemaker_containers.beta.framework import (\n",
    "        content_types,\n",
    "        encoders,\n",
    "        env,\n",
    "        modules,\n",
    "        transformer,\n",
    "        worker,\n",
    "        server,\n",
    "    )\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "feature_columns = [\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    \"housingMedianAge\",\n",
    "    \"totalRooms\",\n",
    "    \"totalBedrooms\",\n",
    "    \"population\",\n",
    "    \"households\",\n",
    "    \"medianIncome\",\n",
    "]\n",
    "label_column = \"medianHouseValue\"\n",
    "\n",
    "base_dir = \"/opt/ml/processing\"\n",
    "base_output_dir = \"/opt/ml/output/\"\n",
    "\n",
    "# feature build logic \n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(f\"{base_dir}/input/raw_data_all.csv\")\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df[feature_columns], df[label_column], test_size=0.33)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train.values) \n",
    "    x_train[feature_columns] = scaler.transform(x_train) \n",
    "\n",
    "    train_dataset = pd.concat([x_train, y_train], axis=1) \n",
    "    test_dataset = pd.concat([x_test, y_test], axis=1)\n",
    "        \n",
    "    train_dataset.to_csv(f\"{base_dir}/train/train.csv\", header=None, index=None) \n",
    "    test_dataset.to_csv(f\"{base_dir}/test/test.csv\", header=None, index=None)\n",
    "    \n",
    "    # save feature artifact for inference\n",
    "    joblib.dump(scaler, \"model.joblib\")\n",
    "    with tarfile.open(f\"{base_dir}/scaler_model/model.tar.gz\", \"w:gz\") as tar_handle:\n",
    "        tar_handle.add(f\"model.joblib\")\n",
    "\n",
    "# inference functions\n",
    "def input_fn(input_data, content_type):\n",
    "    \"\"\"Parse input data payload\n",
    "    \"\"\"\n",
    "    print(\"Entering preprocessing input fn.\")\n",
    "    if content_type == \"text/csv\":\n",
    "        # Read the raw input data as CSV.\n",
    "        df = pd.read_csv(StringIO(input_data), header=None) \n",
    "        \n",
    "        # If labelled, drop before inference\n",
    "        if len(df.columns) == len(feature_columns) + 1:\n",
    "            df.columns = feature_columns + [label_column]\n",
    "            df=df.drop(columns = label_column)\n",
    "        \n",
    "        # If unlabelled, continue    \n",
    "        elif len(df.columns) == len(feature_columns):\n",
    "            df.columns = feature_columns\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(\"{} not supported by script!\".format(content_type))\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialize fitted model\"\"\"\n",
    "    print(\"Entering preprocessing model fn.\")\n",
    "    preprocessor = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return preprocessor\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"Apply feature transform to data\n",
    "    \"\"\"\n",
    "    print(\"Entering preprocessing predict fn.\")\n",
    "    features = model.transform(input_data.values) \n",
    "    return features\n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    \"\"\"Format prediction output\n",
    "    The default accept/content-type between containers for serial inference is JSON.\n",
    "    \"\"\"\n",
    "    print(\"Entering preprocessing output fn.\")\n",
    "    if accept == \"application/json\":\n",
    "        instances = []\n",
    "        for row in prediction.tolist():\n",
    "            instances.append(row)\n",
    "        json_output = {\"instances\": instances}\n",
    "\n",
    "        return worker.Response(json.dumps(json_output), mimetype=accept)\n",
    "    elif accept == \"text/csv\":\n",
    "        return worker.Response(encoders.encode(prediction, accept), mimetype=accept)\n",
    "    else:\n",
    "        raise RuntimeException(\"{} accept type is not supported by this script.\".format(accept))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5433a2ba-daab-4a0f-9c6f-04daff8d57ce",
   "metadata": {},
   "source": [
    "Define a scikit-learn FrameworkProcessor to wrap feature build script for a Sagemaker Processing Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "86e00bc1-3f49-454a-a577-df2063b2b02c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, FrameworkProcessor\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn_framework_version = \"1.2-1\"\n",
    "\n",
    "sklearn_processor = FrameworkProcessor(\n",
    "    estimator_cls=SKLearn,\n",
    "    framework_version=sklearn_framework_version,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-housing-data-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    code_location=f\"s3://{bucket}/{prefix}/processing\"\n",
    ")\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"scaler_model\", source=\"/opt/ml/processing/scaler_model\", destination = f\"s3://{bucket}/{prefix}/processing\"), \n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination = f\"s3://{bucket}/{prefix}/train\"), \n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\", destination = f\"s3://{bucket}/{prefix}/test\"), \n",
    "    ],\n",
    "    code=\"code/features.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec29eb-9cdb-4c9a-a34d-b535889d260f",
   "metadata": {},
   "source": [
    "Wrap feature script in a Sagemaker Pipelines ProcessingStep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7fdc6e83-c8ac-44d6-be21-d131b5b7ab44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep, CacheConfig\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"30d\")\n",
    "\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"PreprocessData\",\n",
    "    step_args=processor_args,\n",
    "    cache_config=cache_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0046fa-6fa1-4654-b2f9-6c110ccf60da",
   "metadata": {},
   "source": [
    "### 5. Model Training and Inference Script <a name=\"model\"></a><a name=\"model\"></a>\n",
    "\n",
    "Demonstrates SKLearn model training and artifact registration. In custom inference functions, deserialize the model for prediction computation.\n",
    "\n",
    "#### Script Structure\n",
    "\n",
    "Inside the main guard (`if name == __main__`), provide training code with arguments for Sagemaker Training Job.\n",
    "\n",
    "Outside the main guard, define Sagemaker's expected inference functions:\n",
    "* `input_fn`: reads preprocessed input data from the feature step via the relative directory passed into the model step container\n",
    "* `model_fn`: deserializes the tar.gz artifact from the model registry containing any pretrained model artifacts\n",
    "* `predict_fn`: computes model inference predictions\n",
    "* (optional) `output_fn`: can configure additional custom handling of output predictions\n",
    "  \n",
    "Refer to the Sagemaker Python SDK documentation for model-specific inferencing details. If no custom inferencing functions are provided, the default Sagemaker inference handler will run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bab6f2ce-7c5a-4d85-a29c-e0fe41a74406",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/model.py\n",
    "\n",
    "import argparse, os\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "import pathlib\n",
    "import pickle\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "def get_train_data(train_dir):\n",
    "    train_data = pd.read_csv(os.path.join(train_dir, \"train.csv\"))\n",
    "    x_train = train_data.iloc[:,:-1].to_numpy()\n",
    "    y_train = train_data.iloc[:,-1].to_numpy()\n",
    "    print(\"x train\", x_train.shape, \"y train\", y_train.shape)\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "def get_test_data(test_dir):\n",
    "    test_data = pd.read_csv(os.path.join(test_dir, \"test.csv\"))\n",
    "    x_test = test_data.iloc[:,:-1].to_numpy()\n",
    "    y_test = test_data.iloc[:,-1].to_numpy()\n",
    "    print(\"x test\", x_test.shape, \"y test\", y_test.shape)\n",
    "\n",
    "    return x_test, y_test\n",
    "\n",
    "\n",
    "# Model Training\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    feature_columns = [\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    \"housingMedianAge\",\n",
    "    \"totalRooms\",\n",
    "    \"totalBedrooms\",\n",
    "    \"population\",\n",
    "    \"households\",\n",
    "    \"medianIncome\",\n",
    "    ]\n",
    "    \n",
    "    label_column = \"medianHouseValue\"\n",
    "    \n",
    "    # Passing in environment variables and hyperparameters for our training script\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Hyperparamaters\n",
    "    parser.add_argument('--model_dir', type=str)\n",
    "    parser.add_argument(\"--n_estimators\", type=int, default=20)\n",
    "    parser.add_argument('--sm-model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--eval\", type=str, default= \"/opt/ml/processing/evaluation\")\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    n_estimators     = args.n_estimators\n",
    "    model_dir  = args.model_dir\n",
    "    sm_model_dir = args.sm_model_dir\n",
    "    training_dir   = args.train\n",
    "    eval_dir = args.eval\n",
    "    \n",
    "    # Reading in data\n",
    "    df = pd.read_csv(training_dir + '/train.csv',sep=',', header=None)\n",
    "    print(\"Data read into model script:\")\n",
    "    print(df)\n",
    "    \n",
    "    # Split data    \n",
    "    print(\"Training data location: {}\".format(args.train))\n",
    "    print(\"Test data location: {}\".format(args.test))\n",
    "    x_train, y_train = get_train_data(args.train)\n",
    "    x_test, y_test = get_test_data(args.test)\n",
    "    \n",
    "    # Model Building\n",
    "    model = RandomForestRegressor(n_estimators=args.n_estimators)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_preds = model.predict(x_test)\n",
    "    print(\"\\nR2 score on test set :\", model.score(x_test,y_test))\n",
    "    \n",
    "    # Write results to file\n",
    "    eval_results = {\n",
    "        \"Test R2\": model.score(x_test,y_test)\n",
    "    }\n",
    "\n",
    "    # Serializing json\n",
    "    results = json.dumps(eval_results, indent=4)\n",
    "\n",
    "    # Writing serialized eval results to file in container\n",
    "    pathlib.Path(eval_dir).mkdir(parents=True, exist_ok=True)\n",
    "    evaluation_path = f\"{eval_dir}/evaluation.json\"\n",
    "    \n",
    "    with open(f\"{evaluation_path}\", \"w\") as outfile:\n",
    "        outfile.write(results)\n",
    "                \n",
    "    # Save model\n",
    "    joblib.dump(model, os.path.join(args.sm_model_dir, \"model.joblib\"))\n",
    "    \n",
    "    \n",
    "# inference functions\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"Parse input data payload\n",
    "    \"\"\"\n",
    "    print(\"Entering model input_fn.\")\n",
    "    if request_content_type == \"application/json\":\n",
    "        request_body = json.loads(request_body)\n",
    "        inpVar = request_body[\"instances\"]\n",
    "        return inpVar\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports application/json input\")\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Deserialize fitted model\n",
    "    \"\"\"\n",
    "    print(\"Entering model model_fn.\")\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"\n",
    "    Generate model inference predictions\n",
    "    \"\"\"\n",
    "    print(\"Entering model predict_fn.\")\n",
    "    return model.predict(input_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92865baa-9670-4cff-a1b7-eefaad368644",
   "metadata": {},
   "source": [
    "Define SKLearn estimator and wrap model training in TrainingStep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c87b1cbe-59ef-4103-9712-91f2a33447e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "import time\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    sagemaker_session=pipeline_session,\n",
    "    entry_point=\"code/model.py\", \n",
    "    framework_version=sklearn_framework_version, \n",
    "    instance_type=training_instance_type, \n",
    "    role=role\n",
    ")\n",
    "\n",
    "train_args = sklearn_estimator.fit(\n",
    "    {\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "step_train_model = TrainingStep(name=\"TrainSKLearnModel\", step_args=train_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486c336f-6179-42f1-afb1-652fcc8291e6",
   "metadata": {},
   "source": [
    "### 6. Define a model creation step <a name=\"createregister\"></a><a name=\"createregister\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dd43e78f-c7ec-451b-b037-d70e35b90c31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/processing/sklearn-housing-data-process-2023-12-15-21-22-29-101/source/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/processing/sklearn-housing-data-process-2023-12-15-21-22-29-101/source/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker import PipelineModel\n",
    "from sagemaker import image_uris\n",
    "\n",
    "\n",
    "scaler_model_s3 = \"{}/model.tar.gz\".format(\n",
    "    step_process.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    ")\n",
    "\n",
    "scaler_model = SKLearnModel(\n",
    "    model_data=scaler_model_s3,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    entry_point=\"code/features.py\",\n",
    "    framework_version=sklearn_framework_version,\n",
    ")\n",
    "\n",
    "sklearn_model_image_uri = image_uris.retrieve(\n",
    "    framework=\"sklearn\",\n",
    "    region=region,\n",
    "    version=sklearn_framework_version,\n",
    "    py_version=\"py3\",\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "sklearn_model = SKLearnModel(\n",
    "    framework_version = sklearn_framework_version,\n",
    "    model_data=step_train_model.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    entry_point=\"code/model.py\", \n",
    "    role=role,\n",
    ")\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    models=[scaler_model, sklearn_model], role=role, sagemaker_session=pipeline_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "07234c95-5744-430c-b26e-b9388884c223",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "step_create_model = ModelStep(\n",
    "    name=\"PipelineModelCreation\",\n",
    "    step_args=pipeline_model.create(instance_type=create_model_instance_type)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c66cefd-f59b-4c09-b8a2-47bb0935a355",
   "metadata": {},
   "source": [
    "### Define a Model Registration Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "22263a5c-8e8a-40e3-80b3-17afb1ce7376",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "\n",
    "register_args = pipeline_model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[processing_instance_type, training_instance_type],\n",
    "    transform_instances=[config_data[\"BATCH_TRANSFORM_INSTANCE_TYPE\"]],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    ")\n",
    "\n",
    "step_register_pipeline_model = ModelStep(\n",
    "    name=\"PipelineModelRegistration\",\n",
    "    step_args=register_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec21c5b-553b-4165-aca6-e51562fd06ed",
   "metadata": {},
   "source": [
    "### 7. Define a Sagemaker Pipeline<a name=\"pipeline\"></a><a name=\"pipeline\"></a>\n",
    "\n",
    "Wrap the feature building and model building for training and inference in a Sagemaker Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f2d075ce-5972-4c5b-bdeb-80bbb130beb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    parameters=[\n",
    "        training_instance_type,\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        input_data,\n",
    "        model_approval_status,\n",
    "    ],\n",
    "    \n",
    "    steps = [step_process, step_train_model, step_create_model, step_register_pipeline_model]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "73883245-c7ef-4cd9-8c10-77916fe30ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/processing/serial-inference-pipeline/code/285c41c3c73f2437a1b221759a34fd6c/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/code/ece5752bed68960c30544c25e83cd9ee/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Version': '2020-12-01',\n",
       " 'Metadata': {},\n",
       " 'Parameters': [{'Name': 'TrainingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.m5.xlarge'},\n",
       "  {'Name': 'ProcessingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.m5.xlarge'},\n",
       "  {'Name': 'ProcessingInstanceCount', 'Type': 'Integer', 'DefaultValue': 1},\n",
       "  {'Name': 'InputData',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 's3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/housing_data/raw'},\n",
       "  {'Name': 'ModelApprovalStatus',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'Approved'}],\n",
       " 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'},\n",
       "  'TrialName': {'Get': 'Execution.PipelineExecutionId'}},\n",
       " 'Steps': [{'Name': 'PreprocessData',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': {'Get': 'Parameters.ProcessingInstanceType'},\n",
       "      'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'},\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '341280168497.dkr.ecr.ca-central-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['/bin/bash',\n",
       "      '/opt/ml/processing/input/entrypoint/runproc.sh']},\n",
       "    'RoleArn': 'arn:aws:iam::817463428454:role/service-role/AmazonSageMaker-ExecutionRole-20230919T125063',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Parameters.InputData'},\n",
       "       'LocalPath': '/opt/ml/processing/input',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/processing/serial-inference-pipeline/code/285c41c3c73f2437a1b221759a34fd6c/sourcedir.tar.gz',\n",
       "       'LocalPath': '/opt/ml/processing/input/code/',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'entrypoint',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/code/ece5752bed68960c30544c25e83cd9ee/runproc.sh',\n",
       "       'LocalPath': '/opt/ml/processing/input/entrypoint',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'scaler_model',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/processing',\n",
       "        'LocalPath': '/opt/ml/processing/scaler_model',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'train',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/train',\n",
       "        'LocalPath': '/opt/ml/processing/train',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'test',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/test',\n",
       "        'LocalPath': '/opt/ml/processing/test',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}},\n",
       "   'CacheConfig': {'Enabled': True, 'ExpireAfter': '30d'}},\n",
       "  {'Name': 'TrainSKLearnModel',\n",
       "   'Type': 'Training',\n",
       "   'Arguments': {'AlgorithmSpecification': {'TrainingInputMode': 'File',\n",
       "     'TrainingImage': '341280168497.dkr.ecr.ca-central-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3'},\n",
       "    'OutputDataConfig': {'S3OutputPath': 's3://sklearn-mlops-inf-pipeline-demo/'},\n",
       "    'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "    'ResourceConfig': {'VolumeSizeInGB': 30,\n",
       "     'InstanceCount': 1,\n",
       "     'InstanceType': {'Get': 'Parameters.TrainingInstanceType'}},\n",
       "    'RoleArn': 'arn:aws:iam::817463428454:role/service-role/AmazonSageMaker-ExecutionRole-20230919T125063',\n",
       "    'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.PreprocessData.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ContentType': 'text/csv',\n",
       "      'ChannelName': 'train'},\n",
       "     {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.PreprocessData.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ContentType': 'text/csv',\n",
       "      'ChannelName': 'test'}],\n",
       "    'HyperParameters': {'sagemaker_submit_directory': '\"s3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/code/01d1062377d994b70865acd41eef667e/sourcedir.tar.gz\"',\n",
       "     'sagemaker_program': '\"model.py\"',\n",
       "     'sagemaker_container_log_level': '20',\n",
       "     'sagemaker_region': '\"ca-central-1\"'},\n",
       "    'DebugHookConfig': {'S3OutputPath': 's3://sklearn-mlops-inf-pipeline-demo/',\n",
       "     'CollectionConfigurations': []},\n",
       "    'ProfilerConfig': {'S3OutputPath': 's3://sklearn-mlops-inf-pipeline-demo/',\n",
       "     'DisableProfiler': False}}},\n",
       "  {'Name': 'PipelineModelCreation-CreateModel',\n",
       "   'Type': 'Model',\n",
       "   'Arguments': {'ExecutionRoleArn': 'arn:aws:iam::817463428454:role/service-role/AmazonSageMaker-ExecutionRole-20230919T125063',\n",
       "    'Containers': [{'Image': '341280168497.dkr.ecr.ca-central-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3',\n",
       "      'Environment': {'SAGEMAKER_PROGRAM': 'features.py',\n",
       "       'SAGEMAKER_SUBMIT_DIRECTORY': 's3://sklearn-mlops-inf-pipeline-demo/sagemaker-scikit-learn-2023-12-15-21-22-29-558/sourcedir.tar.gz',\n",
       "       'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
       "       'SAGEMAKER_REGION': 'ca-central-1'},\n",
       "      'ModelDataUrl': 's3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/processing/model.tar.gz'},\n",
       "     {'Image': '341280168497.dkr.ecr.ca-central-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3',\n",
       "      'Environment': {'SAGEMAKER_PROGRAM': 'model.py',\n",
       "       'SAGEMAKER_SUBMIT_DIRECTORY': 's3://sklearn-mlops-inf-pipeline-demo/sagemaker-scikit-learn-2023-12-15-21-22-29-652/sourcedir.tar.gz',\n",
       "       'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
       "       'SAGEMAKER_REGION': 'ca-central-1'},\n",
       "      'ModelDataUrl': {'Get': 'Steps.TrainSKLearnModel.ModelArtifacts.S3ModelArtifacts'}}]}},\n",
       "  {'Name': 'PipelineModelRegistration-RegisterModel',\n",
       "   'Type': 'RegisterModel',\n",
       "   'Arguments': {'ModelPackageGroupName': 'PipelineSKLearnModelPackageGroup',\n",
       "    'InferenceSpecification': {'Containers': [{'Image': '341280168497.dkr.ecr.ca-central-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3',\n",
       "       'Environment': {'SAGEMAKER_PROGRAM': 'features.py',\n",
       "        'SAGEMAKER_SUBMIT_DIRECTORY': 's3://sklearn-mlops-inf-pipeline-demo/sagemaker-scikit-learn-2023-12-15-21-23-05-348/sourcedir.tar.gz',\n",
       "        'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
       "        'SAGEMAKER_REGION': 'ca-central-1'},\n",
       "       'ModelDataUrl': 's3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/processing/model.tar.gz'},\n",
       "      {'Image': '341280168497.dkr.ecr.ca-central-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3',\n",
       "       'Environment': {'SAGEMAKER_PROGRAM': 'model.py',\n",
       "        'SAGEMAKER_SUBMIT_DIRECTORY': 's3://sklearn-mlops-inf-pipeline-demo/sagemaker-scikit-learn-2023-12-15-21-23-05-453/sourcedir.tar.gz',\n",
       "        'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
       "        'SAGEMAKER_REGION': 'ca-central-1'},\n",
       "       'ModelDataUrl': {'Get': 'Steps.TrainSKLearnModel.ModelArtifacts.S3ModelArtifacts'}}],\n",
       "     'SupportedContentTypes': ['text/csv'],\n",
       "     'SupportedResponseMIMETypes': ['text/csv'],\n",
       "     'SupportedRealtimeInferenceInstanceTypes': [{'Get': 'Parameters.ProcessingInstanceType'},\n",
       "      {'Get': 'Parameters.TrainingInstanceType'}],\n",
       "     'SupportedTransformInstanceTypes': ['ml.m4.xlarge']},\n",
       "    'ModelApprovalStatus': {'Get': 'Parameters.ModelApprovalStatus'},\n",
       "    'SkipModelValidation': 'None'}}]}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46944c33-68c6-4439-90b5-34720896d453",
   "metadata": {},
   "source": [
    "### 8. Submit the pipeline and start execution <a name=\"submit\"></a><a name=\"submit\"></a>\n",
    "\n",
    "Running steps to upsert the `role_arn` and start the [pipeline execution](https://docs.aws.amazon.com/sagemaker/latest/dg/run-pipeline.html) will kick-off training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b8fc3a95-edc2-4e64-938e-15ee1fa4baf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/processing/serial-inference-pipeline/code/285c41c3c73f2437a1b221759a34fd6c/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/code/ece5752bed68960c30544c25e83cd9ee/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:instance_type is a PipelineVariable (<class 'sagemaker.workflow.parameters.ParameterString'>). Its interpreted value in execution time should not be of GPU types since GPU training is not supported for Scikit-Learn.\n",
      "INFO:sagemaker.processing:Uploaded None to s3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/processing/serial-inference-pipeline/code/285c41c3c73f2437a1b221759a34fd6c/sourcedir.tar.gz\n",
      "INFO:sagemaker.processing:runproc.sh uploaded to s3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/code/ece5752bed68960c30544c25e83cd9ee/runproc.sh\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.get_training_image_uri) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "Using provided s3_resource\n",
      "------- done -------\n"
     ]
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()\n",
    "execution.wait()\n",
    "print(\"------- done -------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af871e1-c0ee-464c-b70c-52494d125512",
   "metadata": {},
   "source": [
    "Get name of the latest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a950bbe5-7083-43cd-a3cf-4ed5b91c6d58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipelines-cqmtuckawika-PipelineModelCreatio-QYzdoR4H69\n"
     ]
    }
   ],
   "source": [
    "sm_model_name = sm.list_models()['Models'][0]['ModelName']\n",
    "\n",
    "print(sm_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039486e0-806b-4b55-b8da-3a315d7a4184",
   "metadata": {},
   "source": [
    "List model registry information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d8e16f55-0098-4f73-b3de-31a4a13c594b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:utils:Identified the latest approved model package: arn:aws:sagemaker:ca-central-1:817463428454:model-package/PipelineSKLearnModelPackageGroup/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ModelPackageGroupName': 'PipelineSKLearnModelPackageGroup', 'ModelPackageVersion': 5, 'ModelPackageArn': 'arn:aws:sagemaker:ca-central-1:817463428454:model-package/PipelineSKLearnModelPackageGroup/5', 'CreationTime': datetime.datetime(2023, 12, 15, 21, 25, 55, 928000, tzinfo=tzlocal()), 'InferenceSpecification': {'Containers': [{'Image': '341280168497.dkr.ecr.ca-central-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3', 'ImageDigest': 'sha256:9b43ef4706faae38d10bdff012a0d1b35ed9c5b3aac9e60c960170f10d29fa51', 'ModelDataUrl': 's3://sklearn-mlops-inf-pipeline-demo/serial-inference-pipeline/processing/model.tar.gz', 'Environment': {'SAGEMAKER_CONTAINER_LOG_LEVEL': '20', 'SAGEMAKER_PROGRAM': 'features.py', 'SAGEMAKER_REGION': 'ca-central-1', 'SAGEMAKER_SUBMIT_DIRECTORY': 's3://sklearn-mlops-inf-pipeline-demo/sagemaker-scikit-learn-2023-12-15-21-23-05-348/sourcedir.tar.gz'}}, {'Image': '341280168497.dkr.ecr.ca-central-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3', 'ImageDigest': 'sha256:9b43ef4706faae38d10bdff012a0d1b35ed9c5b3aac9e60c960170f10d29fa51', 'ModelDataUrl': 's3://sklearn-mlops-inf-pipeline-demo/pipelines-cqmtuckawika-TrainSKLearnModel-gKFLZm4BU1/output/model.tar.gz', 'Environment': {'SAGEMAKER_CONTAINER_LOG_LEVEL': '20', 'SAGEMAKER_PROGRAM': 'model.py', 'SAGEMAKER_REGION': 'ca-central-1', 'SAGEMAKER_SUBMIT_DIRECTORY': 's3://sklearn-mlops-inf-pipeline-demo/sagemaker-scikit-learn-2023-12-15-21-23-05-453/sourcedir.tar.gz'}}], 'SupportedTransformInstanceTypes': ['ml.m4.xlarge'], 'SupportedRealtimeInferenceInstanceTypes': ['ml.m5.xlarge', 'ml.m5.xlarge'], 'SupportedContentTypes': ['text/csv'], 'SupportedResponseMIMETypes': ['text/csv']}, 'ModelPackageStatus': 'Completed', 'ModelPackageStatusDetails': {'ValidationStatuses': [], 'ImageScanStatuses': []}, 'CertifyForMarketplace': False, 'ModelApprovalStatus': 'Approved', 'CreatedBy': {'IamIdentity': {'Arn': 'arn:aws:sts::817463428454:assumed-role/AmazonSageMaker-ExecutionRole-20230919T125063/sagemaker-pipeline-cqmtuckawika-PipelineModelRegistr', 'PrincipalId': 'AROA34VE6AVTANXNYKS57:sagemaker-pipeline-cqmtuckawika-PipelineModelRegistr'}}, 'MetadataProperties': {'GeneratedBy': 'arn:aws:sagemaker:ca-central-1:817463428454:pipeline/serial-inference-pipeline/execution/cqmtuckawika'}, 'SkipModelValidation': 'None', 'ResponseMetadata': {'RequestId': '74f3d910-9511-4d3f-a3ce-5ae321649b6e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '74f3d910-9511-4d3f-a3ce-5ae321649b6e', 'content-type': 'application/x-amz-json-1.1', 'content-length': '2188', 'date': 'Fri, 15 Dec 2023 21:26:33 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "from utils import get_approved_package\n",
    "\n",
    "pck = get_approved_package(model_package_group_name, sm) \n",
    "model_description = sm.describe_model_package(ModelPackageName=pck[\"ModelPackageArn\"])\n",
    "\n",
    "print(model_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffb225d-d00e-4a9a-b4dd-acc8f7f06a8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 9. Run serial batch inference job <a name=\"inference\"></a>\n",
    "After the pipeline has finished executing, lookup the Sagemaker Model Name and pass it to a Sagemaker Batch Transformation job for inference, along with a raw test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a6c2f7b7-5011-421b-a4a4-e2f46b8827f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: inference-pipelines-batch-2023-12-15-21-26-35-112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................\u001b[34m2023-12-15 21:32:27,838 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-12-15 21:32:27,842 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-12-15 21:32:27,843 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[35m2023-12-15 21:32:27,838 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2023-12-15 21:32:27,842 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2023-12-15 21:32:27,843 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2023-12-15 21:32:28,126 INFO - sagemaker-containers - Module features does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2023-12-15 21:32:28,126 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2023-12-15 21:32:28,126 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2023-12-15 21:32:28,127 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: features\n",
      "  Building wheel for features (setup.py): started\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m2023-12-15 21:32:28,126 INFO - sagemaker-containers - Module features does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m2023-12-15 21:32:28,126 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[35m2023-12-15 21:32:28,126 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m2023-12-15 21:32:28,127 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: features\n",
      "  Building wheel for features (setup.py): started\u001b[0m\n",
      "\u001b[32m2023-12-15 21:32:27,949 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2023-12-15 21:32:27,953 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32m2023-12-15 21:32:27,953 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[32mworker_processes auto;\u001b[0m\n",
      "\u001b[32mdaemon off;\u001b[0m\n",
      "\u001b[32mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[32merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[32mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[32mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[32m}\u001b[0m\n",
      "\u001b[32mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[32m}\u001b[0m\n",
      "\u001b[32m2023-12-15 21:32:28,198 INFO - sagemaker-containers - Module model does not provide a setup.py. \u001b[0m\n",
      "\u001b[32mGenerating setup.py\u001b[0m\n",
      "\u001b[32m2023-12-15 21:32:28,199 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[32m2023-12-15 21:32:28,199 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[32m2023-12-15 21:32:28,199 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[32m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[32mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[32mBuilding wheels for collected packages: model\n",
      "  Building wheel for model (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for features (setup.py): finished with status 'done'\n",
      "  Created wheel for features: filename=features-1.0.0-py2.py3-none-any.whl size=5207 sha256=b16d4577de9deec6002be5f7900c1eeac9258872e06746fa558e71d9b47483c4\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-pmvd_96l/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[35m  Building wheel for features (setup.py): finished with status 'done'\n",
      "  Created wheel for features: filename=features-1.0.0-py2.py3-none-any.whl size=5207 sha256=b16d4577de9deec6002be5f7900c1eeac9258872e06746fa558e71d9b47483c4\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-pmvd_96l/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[34mSuccessfully built features\u001b[0m\n",
      "\u001b[34mInstalling collected packages: features\u001b[0m\n",
      "\u001b[34mSuccessfully installed features-1.0.0\u001b[0m\n",
      "\u001b[35mSuccessfully built features\u001b[0m\n",
      "\u001b[35mInstalling collected packages: features\u001b[0m\n",
      "\u001b[35mSuccessfully installed features-1.0.0\u001b[0m\n",
      "\u001b[32m  Building wheel for model (setup.py): finished with status 'done'\n",
      "  Created wheel for model: filename=model-1.0.0-py2.py3-none-any.whl size=5519 sha256=52eab55ed518aae3e3e78c1d17cc1aae70542a57dfa536942e3916878c8e9cff\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-ifs240a7/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\u001b[0m\n",
      "\u001b[32mSuccessfully built model\u001b[0m\n",
      "\u001b[32mInstalling collected packages: model\u001b[0m\n",
      "\u001b[32mSuccessfully installed model-1.0.0\u001b[0m\n",
      "\u001b[34m[2023-12-15 21:32:32 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2023-12-15 21:32:32 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[35m[2023-12-15 21:32:32 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2023-12-15 21:32:32 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[34m[2023-12-15 21:32:32 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2023-12-15 21:32:32 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2023-12-15 21:32:32 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2023-12-15 21:32:32 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2023-12-15 21:32:32 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2023-12-15 21:32:32 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2023-12-15 21:32:32 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[35m[2023-12-15 21:32:32 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2023-12-15 21:32:32 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2023-12-15 21:32:32 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[32m[2023-12-15 21:32:32 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[32m[2023-12-15 21:32:32 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[32m[2023-12-15 21:32:32 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[32m[2023-12-15 21:32:32 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[32m[2023-12-15 21:32:32 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[32m[2023-12-15 21:32:32 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[32m[2023-12-15 21:32:32 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\n",
      "\u001b[32m2023-12-15 21:32:38,305 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Dec/2023:21:32:39 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Dec/2023:21:32:39 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32mEntering model model_fn.\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [15/Dec/2023:21:32:39 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2023-12-15 21:32:39,642 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mEntering preprocessing input fn.\u001b[0m\n",
      "\u001b[34mEntering preprocessing predict fn.\u001b[0m\n",
      "\u001b[34mEntering preprocessing output fn.\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [15/Dec/2023:21:32:40 +0000] \"POST /invocations HTTP/1.1\" 200 1143121 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mEntering preprocessing input fn.\u001b[0m\n",
      "\u001b[35mEntering preprocessing predict fn.\u001b[0m\n",
      "\u001b[35mEntering preprocessing output fn.\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [15/Dec/2023:21:32:40 +0000] \"POST /invocations HTTP/1.1\" 200 1143121 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32mEntering model model_fn.\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [15/Dec/2023:21:32:40 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2023-12-15 21:32:40,548 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[32mEntering model model_fn.\u001b[0m\n",
      "\u001b[32mEntering model input_fn.\u001b[0m\n",
      "\u001b[32mEntering model predict_fn.\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [15/Dec/2023:21:32:41 +0000] \"POST /invocations HTTP/1.1\" 200 102995 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[36m2023-12-15T21:32:40.357:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "input_data_path = 's3://{}/{}'.format(sagemaker_session.default_bucket(), f\"{prefix}/test/test.csv\") \n",
    "output_data_path = 's3://{}/{}'.format(sagemaker_session.default_bucket(), f'{prefix}/batch-transform/output')\n",
    "\n",
    "transform_job = sagemaker.transformer.Transformer(\n",
    "    model_name = sm_model_name,\n",
    "    instance_count = int(config_data[\"BATCH_TRANSFORM_INSTANCE_COUNT\"]),\n",
    "    instance_type = config_data[\"BATCH_TRANSFORM_INSTANCE_TYPE\"],\n",
    "    strategy = 'MultiRecord',\n",
    "    assemble_with = 'Line',\n",
    "    output_path = output_data_path,\n",
    "    base_transform_job_name='inference-pipelines-batch',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    accept = 'text/csv')\n",
    "\n",
    "transform_job.transform(data = input_data_path, \n",
    "                        content_type = 'text/csv', \n",
    "                        split_type = 'Line',\n",
    "                        join_source='Input')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1281fefd-2e16-4d49-aadc-0bb5d38a8454",
   "metadata": {},
   "source": [
    "### 10. Download Inference Predictions<a name=\"download\"></a>\n",
    "\n",
    "After the batch transform job has completed, you can download and read inference predictions for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c62c8eb4-c5cd-4d52-9cdb-6312242f123f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serial-inference-pipeline/batch-transform/output/test.csv.out\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "####### LIST FILES IN S3 #########\n",
    "res = s3.list_objects_v2(Bucket=bucket, Prefix=f\"{prefix}/batch-transform/output\")\n",
    "                         \n",
    "# select the files\n",
    "for item in res[\"Contents\"]:\n",
    "    print(item['Key'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "698e9277-1088-4289-acec-844bfc844a95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "FILE_NAME = \"batch_inference_preds.csv\"\n",
    "BUCKET_NAME = bucket\n",
    "OBJECT_NAME = f\"{prefix}/batch-transform/output/test.csv.out\"\n",
    "\n",
    "s3.download_file(BUCKET_NAME, OBJECT_NAME, FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "698050e7-f393-4de6-b03e-cf15acee0a36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "      <th>predictedTarget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-118.36</td>\n",
       "      <td>34.07</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>4.7019</td>\n",
       "      <td>0.822200</td>\n",
       "      <td>0.736840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-121.41</td>\n",
       "      <td>38.64</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>1.9167</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.144690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-117.87</td>\n",
       "      <td>33.84</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2395.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>5.1182</td>\n",
       "      <td>0.498400</td>\n",
       "      <td>0.434500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.02</td>\n",
       "      <td>38.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3899.0</td>\n",
       "      <td>763.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>3.2061</td>\n",
       "      <td>0.240800</td>\n",
       "      <td>0.262640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-119.73</td>\n",
       "      <td>36.31</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2440.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1579.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2.8281</td>\n",
       "      <td>0.120400</td>\n",
       "      <td>0.176340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6807</th>\n",
       "      <td>-117.91</td>\n",
       "      <td>33.63</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3442.0</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>1427.0</td>\n",
       "      <td>977.0</td>\n",
       "      <td>3.1985</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>0.534670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6808</th>\n",
       "      <td>-120.86</td>\n",
       "      <td>37.76</td>\n",
       "      <td>32.0</td>\n",
       "      <td>964.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>3.0917</td>\n",
       "      <td>0.177800</td>\n",
       "      <td>0.275460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6809</th>\n",
       "      <td>-122.43</td>\n",
       "      <td>37.81</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3275.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>3.7679</td>\n",
       "      <td>1.000002</td>\n",
       "      <td>0.700341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6810</th>\n",
       "      <td>-121.91</td>\n",
       "      <td>36.59</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>966.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>4.6964</td>\n",
       "      <td>0.582600</td>\n",
       "      <td>0.553750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811</th>\n",
       "      <td>-117.20</td>\n",
       "      <td>34.04</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1762.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>5.9915</td>\n",
       "      <td>0.306400</td>\n",
       "      <td>0.351240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6812 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      longitude  latitude  housingMedianAge  totalRooms  totalBedrooms  \\\n",
       "0       -118.36     34.07              48.0      1740.0          360.0   \n",
       "1       -121.41     38.64              38.0      1384.0          287.0   \n",
       "2       -117.87     33.84              17.0      2395.0          410.0   \n",
       "3       -122.02     38.26              20.0      3899.0          763.0   \n",
       "4       -119.73     36.31              20.0      2440.0          433.0   \n",
       "...         ...       ...               ...         ...            ...   \n",
       "6807    -117.91     33.63              20.0      3442.0         1526.0   \n",
       "6808    -120.86     37.76              32.0       964.0          198.0   \n",
       "6809    -122.43     37.81              39.0      3275.0          837.0   \n",
       "6810    -121.91     36.59              31.0      2034.0          335.0   \n",
       "6811    -117.20     34.04              23.0      1762.0          267.0   \n",
       "\n",
       "      population  households  medianIncome  medianHouseValue  predictedTarget  \n",
       "0          748.0       357.0        4.7019          0.822200         0.736840  \n",
       "1          682.0       280.0        1.9167          0.128800         0.144690  \n",
       "2         1224.0       399.0        5.1182          0.498400         0.434500  \n",
       "3         2198.0       779.0        3.2061          0.240800         0.262640  \n",
       "4         1579.0       400.0        2.8281          0.120400         0.176340  \n",
       "...          ...         ...           ...               ...              ...  \n",
       "6807      1427.0       977.0        3.1985          0.212600         0.534670  \n",
       "6808       623.0       201.0        3.0917          0.177800         0.275460  \n",
       "6809      1137.0       725.0        3.7679          1.000002         0.700341  \n",
       "6810       966.0       322.0        4.6964          0.582600         0.553750  \n",
       "6811      1132.0       279.0        5.9915          0.306400         0.351240  \n",
       "\n",
       "[6812 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = [\n",
    "    \"longitude\",\n",
    "    \"latitude\",\n",
    "    \"housingMedianAge\",\n",
    "    \"totalRooms\",\n",
    "    \"totalBedrooms\",\n",
    "    \"population\",\n",
    "    \"households\",\n",
    "    \"medianIncome\",\n",
    "    \"medianHouseValue\",\n",
    "    \"predictedTarget\"\n",
    "]\n",
    "\n",
    "inf_results = pd.read_csv(\"batch_inference_preds.csv\", names=columns)\n",
    "\n",
    "display(inf_results)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ca-central-1:310906938811:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
